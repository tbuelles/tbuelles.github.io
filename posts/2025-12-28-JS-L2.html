<!doctype html>
<html>

<head>
  <meta charset="utf-8" />
  <title>JS — Tim-Henrik Buelles</title>
  <meta name="author" content="Tim-Henrik Buelles" />
  <meta name="viewport" content="width=device-width; initial-scale=1.0" />
  <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" />
  <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Noto+Serif:400,700,400italic|Open+Sans:700,400" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <link rel="stylesheet" type="text/css" href="../assets/css/home.css" />
  <script src="../assets/js/home.js" defer></script>
</head>

<body>
  <div class="container">

    <div class="button"></div>

    <header class="site-header">
      <a class="link-bold back-left" href="/blog.html" aria-label="Blog"><i class="fa fa-arrow-left"></i> Blog</a>
      <div class="title-wrap">
        <h1>Your model needs James–Stein</h1>
        <div class="post-meta"><span></span>December 28, 2025</div>
      </div>
    </header>

    <!-- Body -->
    <div class="section">

      <h3>Intro</h3>
      <p>
        <!-- Motivation: why shrinkage shows up in ML, why JS is surprising, what we'll connect to. -->
      </p>
      <hr class="header-separator">

      <h3>Setup: Normal Means as a “One-Sample” Regression</h3>
      <p>
        <!-- Define y ∈ R^k, y = μ + ε, ε ~ N(0, σ^2 I), σ known (σ=1).
             Explain why this is “linear regression with X=I”. -->
      </p>
      <hr class="header-separator">

      <h3>MLE / Least Squares</h3>
      <p>
        <!-- Derive μ_hat_MLE = y; risk = k σ^2. -->
      </p>
      <hr class="header-separator">

      <h3>James–Stein Estimator</h3>
      <p>
        <!-- Present μ_hat_JS and μ_hat_JS^+; intuition: data-adaptive shrinkage; mention k≥3. -->
      </p>
      <hr class="header-separator">

      <h3>L2 Regularization (Ridge) in the Same Model</h3>
      <p>
        <!-- Solve argmin ||y-μ||^2 + λ||μ||^2; show constant shrink μ_hat_ridge = 1/(1+λ) y.
             Contrast: constant vs data-adaptive shrink. -->
      </p>
      <hr class="header-separator">

      <h2>From Estimators to Training: Weight Decay vs L2 Regularization</h2>

      <h3>Objective-level L2 Regularization</h3>
      <p>
        <!-- Define minimize L(θ) + (λ/2)||θ||^2; connect to MAP / Gaussian prior. -->
      </p>
      <hr class="header-separator">

      <h3>Update-level Weight Decay</h3>
      <p>
        <!-- Show θ_{t+1} = (1-ηλ)θ_t - η∇L(θ_t); clarify when equivalent to L2 penalty and when not (e.g. AdamW). -->
      </p>
      <hr class="header-separator">

      <h2>A Tiny Worked Example</h2>
      <p>
        <!-- Pick k=10, σ=1; show shrink factors numerically; maybe plot (optional later). -->
      </p>
      <hr class="header-separator">

      <h2>Neural Network Intuition</h2>
      <p>
        <!-- High-level: many parameters, implicit/explicit shrinkage; JS-like = adaptive / hierarchical regularization. -->
      </p>
      <hr class="header-separator">

      <h2>Appendix</h2>

      <h3>Stein’s Lemma and SURE (Sketch)</h3>
      <p>
        <!-- Brief: why JS dominates MLE; cite Stein’s unbiased risk estimate. -->
      </p>
      <hr class="header-separator">

      <h3>References</h3>
      <p>
        <!-- Add refs: Stein 1956, James–Stein 1961, ridge regression / Tikhonov, decoupled weight decay (AdamW). -->
      </p>

    </div>

    <div class="footer"> Last updated December 28, 2025</div>

  </div>
</body>

</html>
