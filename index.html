<!doctype html>

<html>
<head>
	<meta charset="utf-8">
	<title>Tim-Henrik Buelles</title>
	<meta name="author" content="Tim-Henrik Buelles"/>
	<meta name="viewport" content="width=device-width; initial-scale=1.0">
	<link rel="stylesheet" type="text/css" href="home.css">
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css">
	<link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Noto+Serif:400,700,400italic|Open+Sans:700,400" />
    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
</head>

<body>
	<div class="container">
		<div class="section profile">
            <div class="profile-info">
                <h1>Tim-Henrik Buelles</h1>
                <p> thbuelles (at) gmail (dot) com </p>
                <p>
                    <a href="https://scholar.google.com/citations?user=cOVOnbUAAAAJ&hl=en"> Google Scholar </a>
                    &nbsp
                    <a href="https://github.com/tbuelles/"> GitHub </a> </p>
                <div id="outer-div-social-media">
                    <div>
                        <a class="social-media" href="mailto:tbuelles@caltech.edu" target="_blank"><i class="contact-icon fa fa-envelope"></i></a>
                        <!-- <a class="social-media" href="https://github.com/tbuelles" target="_blank"><i class="contact-icon fa-brands fa-github"></i></a> -->
                        <a class="social-media" href="https://www.linkedin.com/in/tbuelles/" target="_blank"><i class="contact-icon fa-brands fa-linkedin-in"></i></a>
                        <a class="social-media" href="https://www.strava.com/athletes/49576806" target="_blank"><i class="contact-icon fa-brands fa-strava"></i></a>
                    </div>
                </div>
            </div>
            <div class="profile-img">
                <div class="profile-img-wrap">
                    <img src="thbuelles.jpg" title="Tim" alt="Tim Profile Image"/>
                </div>
            </div>
        </div>

        <div class="section">

    		<h2 id="bio">About</h2>
    		<ul>
                <li>
                I'm a research scientist at Pythia Labs. My current research focuses on generative modeling.
                </li>

                <!-- <li>
                I received my PhD degree in CS at the University of Chicago in 2017. I
                was very fortunate to be advised by Prof. John Lafferty.
                <br> <br>
                During my PhD, I worked in the intersection of machine learning,
                optimization and statistics.  My research centered around developing
                novel computationally efficient methods with theoretical guarantees for
                challenging machine learning problems, with an emphasis on finding exact
                solutions for nonconvex problems.
                </li>

                <li>
                I worked as a postdoc researcher in the Statistics Department, Wharton School,
                University of Pennsylvania. I worked on differential privacy and statistical inference
                there.
                </li>

                <li>
                Prior to Penn, I was a research scientist in Facebook from 2017 to 2019.
                <br> <br>
                Together with my teammates, I help Facebook build its distributed training system
                for Ads recommendation models. My work
                concentrates on distributed optimization algorithms and system
                architecture design.
                </li>

                <li>
                Earlier, I got my master degree in Max Planck Institute for Informatics
                and my bachelor degree in Zhejiang University.
                </li>
    		</ul> -->
        </div>

        <div class="section">

    		<h2 id="publication">Papers</h2>
    		<!-- <ul>
                <li>
                    <p>
                        <strong>
                            Diffusion World Model
                        </strong><br/>
                        Zihan Ding, Amy Zhang, Yuandong Tian, <strong>Qinqing Zheng</strong> <br/>
                        <a class="paper-pub" href= "https://arxiv.org/abs/2402.03570" target="_blank">[paper]</a>
                    </p>
    			</li>

                <li>
                    <p>
                        <strong>
                           Guided Flows for Generative Modeling and Decision Making
                        </strong><br/>
                        <strong>Qinqing Zheng</strong>, Matt Le, Neta Shaul, Yaron Lipman, Aditya Grover, Ricky T. Q. Chen<br/>
                        <a class="paper-pub" href= "https://arxiv.org/abs/2311.13443" target="_blank">[paper]</a>
                    </p>
    			</li>

                <li>
                    <p>
                        <strong>
                            Dual RL: Unification and New Methods for Reinforcement and Imitation Learning
                        </strong><br/>
                        <span style="color: #2a7ae2"> ICLR 2024 </span>
                        <span style="color: #ff5252">(Spotlight)</span> <br/>
                        Harshit Sikchi, <strong>Qinqing Zheng</strong>, Amy Zhang, Scott Niekum <br/>
                        <a class="paper-pub" href= "https://arxiv.org/abs/2302.08560" target="_blank">[paper]</a>
                        <a href="https://github.com/hari-sikchi/DVL">[code]</a>
                    </p>
    			</li>

                <li>
                    <p>
                        <strong> Semi-Supervised Offline Reinforcement Learning with Action-Free Trajectories </strong><br/>
                        <strong>Qinqing Zheng</strong>, Mikael Henaff, Brandon Amos, Aditya Grover<br/>
                        <span style="color: #2a7ae2"> ICML 2023</span> <br/>
                        <a class="paper-pub" href= "https://arxiv.org/abs/2210.06518" target="_blank">[paper]</a>
                        <a href="https://github.com/facebookresearch/ssorl">[code]</a>
                    </p>
    			</li>

                <li>
                    <p>
                        <strong> ConserWeightive Behavioral Cloning for Reliable Offline Reinforcement Learning </strong><br/>
                        Tung Nguyen, <strong>Qinqing Zheng</strong>, Aditya Grover <br/>
                        <a class="paper-pub" href= "https://arxiv.org/abs/2210.05158" target="_blank">[paper]</a>
                        <a href="https://github.com/tung-nd/cwbc">[code]</a>
                    </p>
    			</li>

                <li>
                    <p>
                        <strong> Latent State Marginalization as a Low-cost Approach for Improving Exploration </strong><br/>
                        Dinghuai Zhang, Aaron Courville, Yoshua Bengio, <strong>Qinqing
                            Zheng</strong>, Amy Zhang, Ricky T. Q. Chen<br/>
                        <span style="color: #2a7ae2"> ICLR 2023</span> <br/>
                        <a class="paper-pub" href= "https://arxiv.org/abs/2210.00999" target="_blank">[paper]</a>
                    </p>
    			</li>

                <li>
                    <p>
                        <strong> Online Decision Transformer </strong><br/>
                        <strong>Qinqing Zheng</strong>, Amy Zhang, Aditya Grover<br/>
                        <span style="color: #2a7ae2"> ICML 2022</span>
                        <span style="color: #ff5252">(Long Oral Presentation)</span> <br/>
                        <a class="paper-pub" href="https://arxiv.org/abs/2202.05607"
                            target="_blank">[paper]</a>
                        <a href="https://github.com/facebookresearch/online-dt">[code]</a>
                        <a href="./odt_icml22.pdf">[poster]</a>
                    </p>
    			</li>

                <li>
                    <p>
                        <strong> Near-Optimal Confidence Sequences for Bounded Random Variables </strong><br/>
                        Arun Kumar Kuchibhotla*, <strong>Qinqing Zheng*</strong> (*Equal contribution) <br/>
                        <span style="color: #2a7ae2"> ICML 2021 </span>
                        <span style="color: #ff5252">(Spotlight)</span> <br/>
                        <a class="paper-pub" href="https://arxiv.org/abs/2006.05022"
                            target="_blank">[paper]</a>
                        <a href="https://github.com/enosair/bentkus_conf_seq">[code]</a>
                    </p>
    			</li>


                <li>
                    <p>
                        <strong> A Theorem of the Alternative for Personalized Federated Learning </strong></br>
                        Shuxiao Chen, <strong>Qinqing Zheng</strong>,  Qi Long, Weijie Su<br/>
                        Submitted. <br/>
                        <a class="paper-pub" href="https://arxiv.org/abs/2103.01901"
                            target="_blank">[paper]</a>
                    </p>
    			</li>


                <li>
                    <p>
                        <strong> Federated \(f\)-Differential Privacy </strong></br>
                        <strong>Qinqing Zheng</strong>, Shuxiao Chen, Qi Long, Weijie Su<br/>
                        <span style="color: #2a7ae2"> AISTATS 2021 </span> <br/>
                        <a class="paper-pub" href="https://arxiv.org/abs/2102.11158"
                            target="_blank">[paper]</a>
                        <a href="https://github.com/enosair/federated_fdp">[code]</a>
                    </p>
    			</li>


                <li>
                    <p>
                        <strong> Sharp Composition Bounds for Gaussian Differential Privacy via Edgeworth Expansion</strong></br>
                        <strong>Qinqing Zheng</strong>, Jinshuo Dong, Qi Long, Weijie Su<br/>
                        <span style="color: #2a7ae2"> ICML 2020 </span> <br/>
    				    <a class="paper-pub" href="https://arxiv.org/abs/2003.04493"
                        target="_blank">[paper]</a>
                        <a href="https://github.com/enosair/gdp-edgeworth">[code]</a>
                    </p>
    			</li>


                <li>
                    <p><strong>
                        ShadowSync: Performing Synchronization in the Background for Highly Scalable Distributed Training
                    </strong><br/>
                        <strong>Qinqing Zheng</strong>, Bor-Yiing Su, Jiyan Yang, Alisson Azzolini, Qiang Wu, Ou Jin, Shri Karandikar, Hagay Lupesko, Liang Xiong, Eric Zhou
                    <br/>
    				<a class="paper-pub" href="https://arxiv.org/abs/2003.03477"
                        target="_blank">[paper]</a>
    			</li>


                <li>
                    <p><strong>
                        Convergence Analysis for Rectangular Matrix Completion Using Burer-Monteiro Factorization and Gradient Descent
                    </strong><br/>
                        <strong>Qinqing Zheng</strong>, John Lafferty
                    <br/>
    				<a class="paper-pub" href="https://arxiv.org/abs/1605.07051"
                        target="_blank">[paper]</a>
    			</li>

                <li>
                    <p><strong>
                        A Convergent Gradient Descent Algorithm for Rank Minimization and Semidefinite Programming from Random Linear Measurements
                    </strong><br/>
                        <strong>Qinqing Zheng</strong>, John Lafferty
                    <br/>
                    <span style="color: #2a7ae2"> NeurIPS 2015 </span> <br/>
    				<a class="paper-pub" href="http://arxiv.org/abs/1506.06081"
                        target="_blank">[paper]</a>
                    <a href="./sdp_nips15.pdf">[poster]</a>
    			</li>

                <li>
                    <p><strong>
                    Interpolating Convex and Non-Convex Tensor Decompositions via the Subspace Norm
                    </strong><br/>
                    <strong> Qinqing Zheng </strong>, Ryota Tomioka <br/>
                    <span style="color: #2a7ae2"> NeurIPS 2015 </span> <br/>
    				<a class="paper-pub" href="http://arxiv.org/abs/1503.05479"
                        target="_blank">[paper]</a>
                        <a href="https://github.com/enosair/tensor-subspace-norm">[code]</a>
                        <a href="./tensor_nips15.pdf">[poster]</a>
    			</li>
    		</ul> -->
        </div>

        <div class="section">
    		<h2 id="talks">Talks</h2>
    		<!-- <ul>
                <li> Princeton University, Nov 2022 </li>
                <li> UC Berkeley, March 2022 </li>
                <li> Minisymposium on Non-Convex Optimization for Low Complexity Models:
                Theory and Applications, SIAM Optimization Conference, May 2017 </li>
                <li> Microsoft Cambridge Research Seminar, UK, March 2017 </li>
                <li> SILO Seminar Series, University of Wisconsin Madison, Jan 2017 </li>
                <li> Ming Hsieh Institute Series on Mathematical Foundations of Learning
                from Signals and Data, USC, Dec 2016
                </li>
            </ul> -->
        </div>

        <div class="section">
    		<h2 id="reviewer">Review</h2>
    		<!-- <ul>
                <li> <b>Conference</b>: ICML, NeurIPS, AISTATS, ICLR </li>
                <li> <b>Journal</b>: Journal of Machine Learning Research (Editorial Board Reviewer), IEEE Transactions on Signal Processing, Annals of Statistics </li>
            </ul> -->
        </div>



        
        <div class="footer"> Last updated Jun 2024 </div>
       
    </div>

</body>

<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new
    Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-48448003-2', 'auto');
    ga('send', 'pageview');

</script>

</html>

